# -*- mode: ruby -*-
# vi: set ft=ruby :

#macro( log $message )
echo "    "
echo "---------------------------------------------------------------------------------------------------------------"
echo "----- $message"
echo "---------------------------------------------------------------------------------------------------------------"
echo "    "
#end

#set( $mysqlVersion = "mysql-connector-java-5.1.35" )
#set( $requestedBy = "X-Requested-By: ambari" )

Vagrant.configure("2") do |config|
    config.vm.box = "timveil/centos6.6-hdp-base"

    config.vm.box_check_update = true

    config.vbguest.auto_update = true

    config.vbguest.no_remote = true

    config.vbguest.no_install = false

    config.multihostsupdater.aliases = {'$arguments.ip' => ['$arguments.hostname']}

    config.vm.provision "hosts", type: "shell", inline: $hostsFile

    config.vm.provision "logCleanup", type: "shell", inline: $logCleanup,  run: "always"

    config.vm.provision "build", type: "shell", inline: $build

    config.vm.hostname = '$arguments.hostname'

    config.vm.network "private_network", ip: '$arguments.ip'

    config.vm.provider "virtualbox" do |v|
        v.memory = $arguments.memoryInMegabytes
        v.cpus = $arguments.cpus
        v.name = '$arguments.hostname'
    end
end

$hostsFile = <<SCRIPT

cat > /etc/hosts <<EOF
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

$arguments.ip   $arguments.hostname
192.168.66.10   repo.hdp.local
EOF

SCRIPT

$logCleanup = <<SCRIPT

#log("Cleaning Logs")
rm -rf /var/log/ambari-metrics-collector/*
rm -rf /var/log/ambari-metrics-monitor/*
rm -rf /var/log/falcon/*
rm -rf /var/log/flume/*
rm -rf /var/log/hadoop/hdfs/*
rm -rf /var/log/hadoop/mapreduce/*
rm -rf /var/log/hadoop/yarn/*
rm -rf /var/log/hadoop-mapreduce/mapred/*
rm -rf /var/log/hadoop-yarn/yarn/*
rm -rf /var/log/hadoop-yarn/nodemanager/*
rm -rf /var/log/hadoop-httpfs/*
rm -rf /var/log/hbase/*
rm -rf /var/log/hive/*
rm -rf /var/log/kafka/*
rm -rf /var/log/knox/*
rm -rf /var/log/oozie/*
rm -rf /var/log/ranger/*
rm -rf /var/log/sqoop/*
rm -rf /var/log/storm/*
rm -rf /var/log/webhcat/*
rm -rf /var/log/zookeeper/*

rm -rf /tmp/hive/*
rm -rf /tmp/hcat/*
rm -rf /tmp/ambari-qa/*
rm -rf /tmp/root/*

SCRIPT

$build = <<SCRIPT

#log("Cleaning YUM")
yum clean all

#if( $arguments.updateLibraries )
#log("Updating YUM")
yum update -y -q
#end

#log("Deleting YUM History")
yum history new


#if( $arguments.containsFileView()) )
#log("Adding Admin User")
useradd -G hdfs admin
usermod -a -G users admin
usermod -a -G hadoop admin
#end

#log("Getting Ambari YUM Repo")
wget -q http://repo.hdp.local/ambari/centos6/ambari.repo -O /etc/yum.repos.d/ambari.repo

#log("Installing Ambari Server and Agent")
yum install ambari-server ambari-agent unzip -y -q

#log("Updating Ambari Agent Hostname")
sed -i "s/^hostname=localhost/hostname=$arguments.hostname/g" /etc/ambari-agent/conf/ambari-agent.ini

#log("Downloading New MySQL Connector Jar")
wget -q http://dev.mysql.com/get/Downloads/Connector-J/${mysqlVersion}.zip -O /usr/share/java/${mysqlVersion}.zip
cd /usr/share/java
unzip -q ${mysqlVersion}.zip

#log("Running Ambari Server setup")
ambari-server setup -s -j $JAVA_HOME

#log("Updating MySql Connector Jar")
ambari-server setup --jdbc-driver=/usr/share/java/${mysqlVersion}/${mysqlVersion}-bin.jar --jdbc-db=mysql

#if( $arguments.containsFileView()) )
#log("Downloading Ambari Files View")
wget -q http://dev.hortonworks.com.s3.amazonaws.com/HDP-LABS/Projects/Ambari/2.0.0-Preview/contrib/views/files-0.1.0-SNAPSHOT.jar -O /var/lib/ambari-server/resources/views/files-0.1.0-SNAPSHOT.jar
#end

#if( $arguments.containsHiveView()) )
#log("Downloading Ambari Hive View")
wget -q http://dev.hortonworks.com.s3.amazonaws.com/HDP-LABS/Projects/Ambari/2.0.0-Preview/contrib/views/hive-0.1.0-SNAPSHOT.jar -O /var/lib/ambari-server/resources/views/hive-0.1.0-SNAPSHOT.jar
#end

#log("Starting Ambari Server")
ambari-server start

#log("Starting Ambari Agent")
ambari-agent start

#log("Executing POST to Create Blueprint")
curl --silent --show-error -H "${requestedBy}" -X POST -d @/vagrant/$bluprentJsonFileName -u admin:admin $arguments.getBlueprintUrl()

#log("Executing PUT to Create HDP Repo")
curl --silent --show-error -H "${requestedBy}" -X PUT -d @/vagrant/$hdpRepoJsonFileName -u admin:admin $arguments.getHdpRepoUrl()

#log("Executing PUT to Create HDP-Utils Repo")
curl --silent --show-error -H "${requestedBy}" -X PUT -d @/vagrant/$hdpUtilsRepoJsonFileName -u admin:admin $arguments.getHdpUtilsRepoUrl()

#log("Executing POST to Install Cluster")
curl --silent --show-error -H "${requestedBy}" -X POST -d @/vagrant/$createClusterJsonFileName -u admin:admin $arguments.getClusterUrl()

#log("Waiting for Cluster Install to Finish")
RET=0
until [ ${RET} -eq 1 ]; do
    RET=$(curl --silent --show-error -H "${requestedBy}" -X GET -u admin:admin $arguments.getCheckStatusUrl() 2>&1 | grep -c "COMPLETED")
    echo "."
    sleep 30
done

#*
#if( $arguments.containsFileView()) )
#log("Executing POST to Create Files View")
curl --silent --show-error -H "${requestedBy}" -X POST -d @/vagrant/$filesViewJsonFileName -u admin:admin $arguments.getFilesViewUrl()
#end

#if( $arguments.containsHiveView()) )
#log("Executing POST to Create Hive View")
curl --silent --show-error -H "${requestedBy}" -X POST -d @/vagrant/$hiveViewJsonFileName -u admin:admin $arguments.getHiveViewUrl()
#end

#if( $arguments.containsHiveView() || $arguments.containsFileView()) )
#log("Stopping Ambari Server")
ambari-server stop

#log("Starting Ambari Server")
ambari-server start
#end
*#

#log("Cluster Install Complete!")

SCRIPT